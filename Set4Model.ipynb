{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVeNu37qzQaP"
      },
      "source": [
        "# Feature selection\n",
        "\n",
        "Using Bayesian Information Criterion (BIC), we calculate it based on every subset of features of size 1 to 6. Then, we select the features with the lowest BIC to train our model on.\n",
        "\n",
        "The BIC evaluates the tradeoff between the model's fit and its complexity. This allows us to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR34q-o2tXS0",
        "outputId": "459bbcc5-f9ad-4292-ce37-d5c8fedbd7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done with 1-element subsets\n",
            "Best BIC: 222.1677016482091\n",
            "Best features: ['worst perimeter']\n",
            "Done with 2-element subsets\n",
            "Best BIC: 155.1611406813787\n",
            "Best features: ['worst area' 'worst concave points']\n",
            "Done with 3-element subsets\n",
            "Best BIC: 123.36269508812477\n",
            "Best features: ['worst texture' 'worst area' 'worst concave points']\n",
            "Done with 4-element subsets\n",
            "Best BIC: 114.01058850507678\n",
            "Best features: ['radius error' 'worst texture' 'worst area' 'worst concave points']\n",
            "Done with 5-element subsets\n",
            "Best BIC: 110.18011767702438\n",
            "Best features: ['radius error' 'worst texture' 'worst area' 'worst smoothness'\n",
            " 'worst concave points']\n",
            "Done with 6-element subsets\n",
            "Best BIC: 110.18011767702438\n",
            "Best features: ['radius error' 'worst texture' 'worst area' 'worst smoothness'\n",
            " 'worst concave points']\n",
            "\n",
            "Overall best BIC: 110.18011767702438\n",
            "Overall best features: ['radius error' 'worst texture' 'worst area' 'worst smoothness'\n",
            " 'worst concave points']\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "n_features = X.shape[1]\n",
        "best_bic = np.inf\n",
        "best_features = None\n",
        "\n",
        "for k in range(1, 7):\n",
        "  for combo in combinations(range(n_features), k):\n",
        "    # Get the subset of features\n",
        "    X_subset = X[:, combo]\n",
        "\n",
        "    # Add constant column of 1's to serve as the bias term\n",
        "    X_with_const = sm.add_constant(X_subset)\n",
        "\n",
        "    try:\n",
        "      model = sm.Logit(y, X_with_const).fit(disp=False)\n",
        "      bic = model.bic\n",
        "\n",
        "      # BIC is better if it's smaller\n",
        "      if bic < best_bic:\n",
        "        best_bic = bic\n",
        "        best_features = combo\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"combo:\", breast_cancer.feature_names[list(combo)])\n",
        "        continue\n",
        "\n",
        "  print(f\"Done with {k}-element subsets\")\n",
        "  print(\"Best BIC:\", best_bic)\n",
        "  print(\"Best features:\", breast_cancer.feature_names[list(best_features)])\n",
        "\n",
        "print(\"\\nOverall best BIC:\", best_bic)\n",
        "print(\"Overall best features:\", breast_cancer.feature_names[list(best_features)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgVluGJxoucR"
      },
      "source": [
        "## Selected Features\n",
        "\n",
        "Using BIC, 5 features were selected:\n",
        "* radius error [index 10]\n",
        "* worst texture [index 21]\n",
        "* worst area [index 23]\n",
        "* worst smoothness [index 24]\n",
        "* worst concave points [index 27]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX7TXHpovaXl",
        "outputId": "b72f313a-b4ba-4dbb-a6a1-3a3368e5b020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9741258741258744\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# From BIC, the best features correspond to the following indices\n",
        "features = (10, 21, 23, 24, 27)\n",
        "\n",
        "# Load data\n",
        "breast_cancer = load_breast_cancer()\n",
        "\n",
        "# Get the best features based on BIC\n",
        "X = breast_cancer.data[:, list(features)]\n",
        "y = breast_cancer.target\n",
        "\n",
        "avgScore = 0\n",
        "runs = 20\n",
        "\n",
        "for i in range(runs):\n",
        "    # Split data into 75:25\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
        "\n",
        "    # Scale data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "    # Train the logistic regression model\n",
        "    model = LogisticRegression(max_iter=15)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    avgScore += score\n",
        "\n",
        "# getting average score across all runs\n",
        "print(\"Accuracy:\", avgScore/runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZuH9zy3NUJD",
        "outputId": "8fbbd10f-ef1c-44ab-8022-16dc99e08288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 21, 23, 24, 27)\n",
            "best feature: ['radius error' 'worst texture' 'worst area' 'worst smoothness'\n",
            " 'worst concave points']\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "print(best_features)\n",
        "print(\"best feature:\", breast_cancer.feature_names[list(best_features)])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
