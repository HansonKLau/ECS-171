{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6a8c57",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "Using variance inflation factor (VIF) to check for multicollinearity between the variables. Values of 5 or higher indicate a high correlation. Features with high correlation are removed from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f3a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: mean radius with VIF = 63306.17203588469\n",
      "Removing: worst radius with VIF = 7573.943486033555\n",
      "Removing: mean perimeter with VIF = 3901.901687119607\n",
      "Removing: worst perimeter with VIF = 668.3854404127386\n",
      "Removing: mean fractal dimension with VIF = 508.08682464149285\n",
      "Removing: worst smoothness with VIF = 368.0533791867144\n",
      "Removing: worst texture with VIF = 309.54444960438434\n",
      "Removing: worst fractal dimension with VIF = 184.67972071700538\n",
      "Removing: worst symmetry with VIF = 167.30971478504884\n",
      "Removing: mean concavity with VIF = 142.29904340088856\n",
      "Removing: radius error with VIF = 104.99215955661566\n",
      "Removing: worst concave points with VIF = 100.94649021325061\n",
      "Removing: mean smoothness with VIF = 86.99658368431041\n",
      "Removing: mean compactness with VIF = 74.72314541276282\n",
      "Removing: mean area with VIF = 67.47169344522449\n",
      "Removing: worst compactness with VIF = 49.02308700997905\n",
      "Removing: perimeter error with VIF = 43.72833047786977\n",
      "Removing: mean symmetry with VIF = 36.0757931560618\n",
      "Removing: mean texture with VIF = 23.709901129257826\n",
      "Removing: concave points error with VIF = 18.16312090582923\n",
      "Removing: compactness error with VIF = 15.728368747925318\n",
      "Removing: worst area with VIF = 13.976625992787914\n",
      "Removing: mean concave points with VIF = 11.176654130350768\n",
      "Removing: symmetry error with VIF = 8.648327614210078\n",
      "Removing: fractal dimension error with VIF = 7.551747392596707\n",
      "Removing: smoothness error with VIF = 6.005778935127312\n",
      "\n",
      "Best Features:\n",
      "['texture error', 'area error', 'concavity error', 'worst concavity']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "feature_names = breast_cancer.feature_names.tolist()\n",
    "\n",
    "# Computre and return VIF values\n",
    "def compute_vif(X):\n",
    "    return [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Remove features one by one until all VIF values are under 5\n",
    "while True:\n",
    "    vifs = compute_vif(X)\n",
    "    max_vif = max(vifs)\n",
    "    \n",
    "    # Once all VIF values are under 5, it's done\n",
    "    if max_vif < 5:\n",
    "        break\n",
    "\n",
    "    # Remove the feature with the highest VIF\n",
    "    max_index = vifs.index(max_vif)\n",
    "    feature_to_remove = feature_names[max_index]\n",
    "    print(f\"Removing: {feature_to_remove} with VIF = {max_vif}\")\n",
    "    \n",
    "    # Remove the column and its corresponding feature name\n",
    "    X = np.delete(X, max_index, axis=1)\n",
    "    feature_names.pop(max_index)\n",
    "\n",
    "# Final result\n",
    "print(\"\\nBest Features:\")\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795305ad",
   "metadata": {},
   "source": [
    "# Selected Features\n",
    "\n",
    "4 features were chosen based on VIF. The following features were the only features with a VIF value less than 5.\n",
    "\n",
    "texture error (index 11)\n",
    "area error (index 13)\n",
    "concavity error (index 16)\n",
    "worst concavity (index 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d384661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Indicies of features chosen by VIF\n",
    "features = (11, 13, 16, 26)\n",
    "\n",
    "# Load data\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Features from VIF\n",
    "X = breast_cancer.data[:, list(features)]\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split data into 75:25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=15)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75cc31",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "544476e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (before feature selection):  0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# referencing https://www.geeksforgeeks.org/feature-selection-using-random-forest/\n",
    "\n",
    "# Training without feature selection first\n",
    "\n",
    "# Loading breast cancer data\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split data into 75:25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Training random forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy (before feature selection): \", model.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbaadc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "# Selecting best features\n",
    "\n",
    "# Retrieve importance values (Gini Importance)\n",
    "importance_values = model.feature_importances_\n",
    "\n",
    "# Sort in descending order\n",
    "indicesOfSortedValues = np.argsort(importance_values)[::-1]\n",
    "\n",
    "n = 15\n",
    "\n",
    "# Select top n features\n",
    "selectedFeaturesIndicies = indicesOfSortedValues[:n]\n",
    "\n",
    "# new x train with selected features\n",
    "new_X_train = X_train[:, selectedFeaturesIndicies]\n",
    "new_X_test = X_test[:, selectedFeaturesIndicies]\n",
    "\n",
    "# Fit and evaluate model\n",
    "randomClassifierFeatureSelectedModel = RandomForestClassifier()\n",
    "randomClassifierFeatureSelectedModel.fit(new_X_train, y_train)\n",
    "\n",
    "print(\"Accuracy:\", randomClassifierFeatureSelectedModel.score(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee274fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Params: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best CV Accuracy: 0.9553214774281805\n",
      "Test Accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# Testing different hyperparameters\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# parameters to modify\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,          # 5-fold cross-validation\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "# fitting to different models\n",
    "result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Params:\", result.best_params_)\n",
    "\n",
    "# Average accuracy of the 5 cross folds\n",
    "print(\"Best CV Accuracy:\", result.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = result.best_estimator_\n",
    "print(\"Test Accuracy:\", best_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b70384e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def confusion_matrix(y_test, y_pred):\n",
    "  tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] == 0:\n",
    "      if y_test[i] == y_pred[i]:\n",
    "        tn += 1\n",
    "      else:\n",
    "        fp += 1\n",
    "    else:\n",
    "      if y_test[i] == y_pred[i]:\n",
    "        tp += 1\n",
    "      else:\n",
    "        fn += 1\n",
    "\n",
    "  return tp, fp, fn, tn\n",
    "\n",
    "\n",
    "def MCC(tp, fp, fn, tn):\n",
    "  numerator = (tp * tn) - (fp * fn)\n",
    "  denom = sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "  return numerator / denom\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "  # Calculate metrics\n",
    "  tp, fp, fn, tn = confusion_matrix(y_test, y_pred)\n",
    "  mcc = MCC(tp, fp, fn, tn)\n",
    "  ppv = tp / (tp + fp)\n",
    "  tpr = tp / (tp + fn)\n",
    "  tnr = tn / (tn + fp)\n",
    "  fpr = fp / (fp + tn)\n",
    "  fnr = fn / (fn + tp)\n",
    "\n",
    "  print(\"Accuracy:           \", accuracy_score(y_test, y_pred))\n",
    "  print(\"True positive rate: \", tpr)\n",
    "  print(\"True negative rate: \", tnr)\n",
    "  print(\"False positive rate:\", fpr)\n",
    "  print(\"False negative rate:\", fnr)\n",
    "  print(\"Precision:          \", ppv)\n",
    "  print(\"MCC:                \", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02c7f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:            0.986013986013986\n",
      "True positive rate:  0.989247311827957\n",
      "True negative rate:  0.98\n",
      "False positive rate: 0.02\n",
      "False negative rate: 0.010752688172043012\n",
      "Precision:           0.989247311827957\n",
      "MCC:                 0.969247311827957\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    ")\n",
    "\n",
    "# Loading breast cancer data\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split data into 75:25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=144)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "calculate_metrics(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
